{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small><i>This tutorial was put together by [Alexander Fridman](http://www.rocketscience.ai) and [Volha Hedranovich](http://www.rocketscience.ai) for the Lecture Course. Source and license info is on [GitHub](https://github.com/volhahedranovich/jupyter_lectures).</i></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 5. Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture outline\n",
    "\n",
    "1. [NLP Basic Tasks](NLP_Tasks.ipynb)\n",
    "<p></p>\n",
    "2. [Key Python packages for NLP](NLP_Tasks.ipynb#Key-Python-packages-for-NLP)\n",
    "  * NLTK\n",
    "  * spaCy\n",
    "    * <span style=\"color:#757575\">POS Tagger</span>\n",
    "    * <span style=\"color:#757575\">NER</span>\n",
    "    * <span style=\"color:#757575\">Lemmatization</span>\n",
    "<p></p>\n",
    "3. [Case study. Text classification](NLP_Case_Study.ipynb)\n",
    "  * Dataset \n",
    "  * Preprocessing\n",
    "    * <span style=\"color:#757575\">1st level cleaning with regexps</span>\n",
    "    * <span style=\"color:#757575\">Spelling correction</span>\n",
    "    * <span style=\"color:#757575\">Tokenization</span>\n",
    "    * <span style=\"color:#757575\">Stopwords removal</span>\n",
    "    * <span style=\"color:#757575\">Stemming, Lemmatization (Porter stemmer, Snowball stemmer, how does it work)</span>\n",
    "    * <span style=\"color:#757575\">Synonyms replacement</span>\n",
    "    * <span style=\"color:#757575\">Replacing negations with antonyms</span>\n",
    "    * <span style=\"color:#757575\">Building of N-gramms, chunking</span>\n",
    "  * Building of corpus vocabulary\n",
    "    * <span style=\"color:#757575\">Selection of most meaning words</span>\n",
    "    * <span style=\"color:#757575\">Meaning less terms removal</span>\n",
    "  * Vectorization\n",
    "    * <span style=\"color:#757575\">Dummy CountVectoriser (BOW)</span>\n",
    "    * <span style=\"color:#757575\">TfIdf</span>\n",
    "    * <span style=\"color:#757575\">Hashing trick</span>\n",
    "    * <span style=\"color:#757575\">Sent2Vec</span>\n",
    "    * <span style=\"color:#757575\">Word2Vec</span>\n",
    "    * <span style=\"color:#757575\">Doc2Vec</span>\n",
    "  * Classification with any algo\n",
    "<p></p><p></p>\n",
    "4. [Sequence data approach. Using RNNs for text classification](NLP_RNN.ipynb)\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework\n",
    "\n",
    "Take part in the challenge **Predict the Happiness**.\n",
    "\n",
    "Problem Statement, Data and Submission form see [here](https://www.hackerearth.com/problem/machine-learning/predict-the-happiness/).\n",
    "\n",
    "Share your best scores in the Slack channel <span style=\"color:#33742c\">`#nlp`</span>, in the thread (available on the tag <span style=\"color:#33742c\">*#nlp-homework1*</span>).\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of abbreviations\n",
    "\n",
    "NLP &#8212; Natural Language Processing (NLP)\n",
    "\n",
    "NLTK &#8212; Natural Language Toolkit\n",
    "\n",
    "POS &#8212; Part-Of-Speech\n",
    "\n",
    "NER &#8212; Named Entity Recognition\n",
    "\n",
    "RegExp &#8212; Regular Expressions\n",
    "\n",
    "BOW &#8212; Bag of Words\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "1. Jacob Perkins. [Python 3 Text Processing with NLTK 3 Cookbook](https://www.packtpub.com/application-development/python-3-text-processing-nltk-3-cookbook)\n",
    "2. The Stanford Natural Language Processing Group. [Software](https://nlp.stanford.edu/software/)\n",
    "3. Platform for building Python programs to work with human language data [NLTK](http://www.nltk.org/)\n",
    "4. Python library for NLP [spaCy](https://spacy.io/usage/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy import displacy\n",
    "import en_core_web_sm\n",
    "\n",
    "from pywsd.lesk import simple_lesk\n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
